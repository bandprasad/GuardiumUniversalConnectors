###  Date Modified : 10/30/2023 10:50 P.M
# --- TO DO : 1. Convert the ISO timestamp to epoc
# ------      2. Populate Catalog Objects from Array


input {
  kafka {
    bootstrap_servers => "<<BOOT_STRAP_SERVER_DETAILS_HERE>>"
    client_dns_lookup => "use_all_dns_ips"
    jaas_path => "<<PATH_TO_JAAS_CONF_FILE>>"
    client_id => "<<CLIENT_ID>>"
    group_id => "<<GROUP_ID>>"
    ssl_truststore_location => "<<TRUST_STORE_JKS_FILE_LOCATION>>"
    ssl_truststore_password => "<<TRUST_STORE_PASSWORD>>"
    security_protocol => "SASL_SSL"
    sasl_mechanism => "SCRAM-SHA-512"
    id => "<<ID_HERE>>"
    partition_assignment_strategy => "cooperative_sticky"
    codec => "json"
    decorate_events => "basic"
    topics => [ "hadoop_hdfs_audit" ]
  }
}



filter {
  mutate {
    add_field => { "[event][module]" => "hadoop" }
    add_field => { "[event][dataset]" => "hadoop.impala_audit" }
  }

### https://stackoverflow.com/questions/2578194/what-are-ddl-and-dml

  grok {
    match => { "[event][original]" => "^{.*?:(?<tmp>(.|\n)*)}" }
    tag_on_failure => "_grokparsefailure_to_tmp"
  }
  mutate {
    gsub => [
      "tmp", '\"', '"'
      ]
  }
  json {
    source => "tmp"
    target => "tmp_json"
    tag_on_failure => "_jsonparsefailure_tmp_to_tmp_json"
  }


  grok {
        match => { "[tmp_json][network_address]" => "^(.*?::.*?:)?(?<[source][ip]>\d+\.\d+\.\d+\.\d+):(?<[source][port]>\d+)" }
        tag_on_failure => "_grokparsefailure_to_tmp_json"
      }
#  mutate {
#    rename => { "[tmp_json][start_time]" => "[event][created]" }
#  }
   
  
#  date {
#    match => ["[event][created]","yyyy-MM-dd HH:mm:ss.SSSSSS"  ]
#    timezone => "GMT"
#    locale => "en"
#    target => "[event][created]"
#    tag_on_failure => "_dateparsefailure_ec"
#  }
#  if "_dateparsefailure_ec" in [tags]  {
#    mutate {
#      remove_field => ["[event][created]"]
#    }
#  }
    mutate {
    	# add_field => { "[GuardRecord][sessionId]" => "" }
    	add_field => { "[GuardRecord][dbName]" => "%{[fields][environment]}" }
    	
        rename => { "[source][ip]" => "[GuardRecord][sessionLocator][clientIp]" }		
        rename => { "[source][port]" => "[GuardRecord][sessionLocator][clientPort]" }				
    	add_field => { "[GuardRecord][sessionLocator][clientIpv6]" => "" }
    	add_field => { "[GuardRecord][sessionLocator][isIpv6]" => "false" } 
    	add_field => { "[GuardRecord][sessionLocator][serverIp]" => "0.0.0.0" }
    	add_field => { "[GuardRecord][sessionLocator][serverIpv6]" => "" }
    	add_field => { "[GuardRecord][sessionLocator][serverPort]" => "-1" }	
        

        add_field => { "[GuardRecord][accessor][dbUser]" => "" }
        add_field => { "[GuardRecord][accessor][osUser]" => "" }
        add_field => { "[GuardRecord][accessor][client_mac]" => "" }
    	add_field => { "[GuardRecord][accessor][clientHostName]" => "" }
    	add_field => { "[GuardRecord][accessor][clientOs]" => "" }
    	add_field => { "[GuardRecord][accessor][commProtocol]" => "" }
    	add_field => { "[GuardRecord][accessor][dataType]" => "TEXT" }
    	add_field => { "[GuardRecord][accessor][dbProtocol]" => "Apache Kafka" }
    	add_field => { "[GuardRecord][accessor][dbProtocolVersion]" => "" }
    	add_field => { "[GuardRecord][accessor][language]" => "IMPALA" }
    	add_field => { "[GuardRecord][accessor][serverDescription]" => "%{[log][file][path]}" }
    	add_field => { "[GuardRecord][accessor][serverHostName]" => "ApacheKafka" }
    	add_field => { "[GuardRecord][accessor][serverOs]" => "" }
    	add_field => { "[GuardRecord][accessor][serverType]" => "Impala" }
    	add_field => { "[GuardRecord][accessor][sourceProgram]" => "" }

    	add_field => { "[GuardRecord][data][construct][fullSql]" => "[]" }
    	add_field => { "[GuardRecord][data][construct][redactedSensitiveDataSql]" => "[]" }
    	add_field => { "[GuardRecord][data][construct][sentences][fields]" => "[]" }
    	add_field => { "[GuardRecord][data][construct][sentences][descendants]" => "[]" }
    	add_field => { "[GuardRecord][data][construct][sentences][objects][schema]" => "" }
    	add_field => { "[GuardRecord][data][construct][sentences][objects][fields]" => "[]" }
    	add_field => { "[GuardRecord][data][construct][sentences][fullSql]" => "%{[tmp_json][sql_statement]}" }
    	add_field => { "[GuardRecord][data][originalSqlCommand]" => "%{[tmp_json][sql_statement]}" }
	
        add_field => { "[GuardRecord][exception][description]" => "NA" }
    	add_field => { "[GuardRecord][exception][exceptionTypeId]" => "NA" }
    	add_field => { "[GuardRecord][exception][sqlString]" => "NA" }

        add_field => { "[GuardRecord][time][minDst]" => "0" }
    	add_field => { "[GuardRecord][time][minOffsetFromGMT]" => "0" }
    	add_field => { "[GuardRecord][time][timestamp]" => "%{[tmp_json][start_time]}" }
		
    }


#  grok {
#    match => { "[event][original]" => '^{"(?<[GuardRecord][time][timestamp]>.*?)":(?<tmp>(.|\n)*)}' }
#  }



#  mutate {
#    convert => { "[GuardRecord][time][timestamp]" => "integer" }
#  }
  
  ruby{
   code => '
     event.set("[GuardRecord][time][timestamp]", Time.parse(event.get("[tmp_json][start_time]")).to_i)
   '
  }

  ruby {
            code => '
                event.set("[GuardRecord][data][construct][sentences]", [{
                    "verb" => "n/A",
                    "descendants" => [],
                    "fields" => [],
                    "objects" => [{
                        "schema" => "N/A",
                        "fields" => [],
						"name" => "N/a",
						"type" => "N/A"
                    }]
                }])
            '
        }
   mutate {

      update => { "[GuardRecord][accessor][dbUser]" => "%{[tmp_json][user]}" }
      update => { "[GuardRecord][data][construct][fullSql]" => "%{[tmp_json][sql_statement]}" }
      update => { "[GuardRecord][data][construct][redactedSensitiveDataSql]" => "%{[tmp_json][sql_statement]}" }

   }

  mutate {
    # rename => { "[fields][environment]" => "[service][name]" }
    #remove_field => [ "input", "service", "destination", "program", "topic_name", "fields", "[event][original]", "tmp_json", "tmp" ]
	remove_field => [ "input", "service", "destination", "program", "topic_name", "fields", "[event][original]" ]
    remove_tag => [ "impala-audit", "beats", "beats_input_codec_plain_applied", "siem-kafka" ]
  }
  prune 
  {
    # whitelist_names => ["tmp_json", "tmp", "GuardRecord"]
	whitelist_names => ["GuardRecord"]
  }
 json_encode {
  source => "[GuardRecord]"
  target => "[GuardRecord]"
  }  
  
}


output {
  stdout {codec => json_lines}
}
